server:
  port: 8080
  servlet:
    context-path: /demo
    encoding:
      force: true   # true = 使用当前配置文件进行编码, 可配合 charset: utf-8 使用

# Spring 配置
spring:
  application:
    name: demo
  main:
    allow-bean-definition-overriding: true # true = 允许后覆盖相同名称的 bean, 防止项目集成后出现重复定义的冲突

  data:
    web:
      pageable:
        one-indexed-parameters: true  # true = 分页查询页码从 1 而不是 0 开始

    redis:
      host: localhost
      port: 6379
      password: "xembec-1rasDi-paztoq"
      timeout: 10s
      lettuce:
        pool:
          max-active: 8
          max-wait: -1s
          max-idle: 8
          min-idle: 0

  # 数据库
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/data?createDatabaseIfNotExist=true&useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai&nullCatalogMeansCurrent=true&allowPublicKeyRetrieval=true
    username: root
    password: "xaTqi5!moNzx#noZcYr"
    type: com.zaxxer.hikari.HikariDataSource
    hikari:
      minimum-idle: 3
      maximum-pool-size: 10
    druid:
      test-while-idle: true
      validation-query: SELECT 1

  # JPA
  jpa:
    show-sql: true        # log 中打印 sql 语句, 便于排查错误
    open-in-view: false   # true = 保持数据库连接直至 controller 执行完

  # 邮件发送
  mail:
    host: smtp.163.com            # 邮箱所属服务器
    username: test8y5Wr@163.com   # 邮箱
    password: ZQCVOJLAPZEGEUZO    # 邮箱 smtp 授权码, 或邮箱密码(取决于邮箱种类)

  task:
    # 线程池
    execution:
      pool:
        max-size: 16
        core-size: 16
        keep-alive: 10s
        queue-capacity: 100
        allow-core-thread-timeout: true
      # 线程名称前缀
      thread-name-prefix: async-task-

    # 定时任务
    scheduling:
      pool:
        size: 10

  # Elasticsearch
  elasticsearch:
    uris: http://localhost:9200
    socket-timeout: 60000
    connection-timeout: 60000
    password:

  # Kafka
  kafka:
    bootstrap-servers: localhost:9092
    template:
      default-topic: demo-topic
    consumer:
      group-id: demo-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 没有 offset 时配置 offset 的规则
      auto-offset-reset: earliest
      # 是否允许自动提交
      enable-auto-commit: false
      # 拉取数据时, 每批次最大数据量
      max-poll-records: 1000
      fetch-max-wait: 3s
      properties:
        isolation.level: read_committed
    listener:
      type: batch
      # 提交模式
      ack-mode: manual_immediate
      idle-event-interval: 10s
      concurrency: 4
      missing-topics-fatal: false
    producer:
      # 消息处理成功的条件: 0 不返回, 1 leader 收到返回成功, all/-1 全员收到返回成功
      acks: 1

  # Neo4j
  neo4j:
    uri: bolt://localhost:7687
    authentication:
      username: neo4j
      password: RVsdbgjs~4921

  # Swagger
  mvc:
    pathmatch:
      matching-strategy: ant_path_matcher

  # Thymeleaf
  thymeleaf:
    check-template-location: false

  # Quartz 任务调度
  quartz:
    scheduler-name: quartzScheduler   # 调度器名称(全局, 定时任务会在同名调度器间自动分配且不会重复执行)
    job-store-type: jdbc              # 存储方式: jdbc(数据库), memory(内存)
    auto-startup: true                # 是否在初始化后自动启动定时任务
    wait-for-jobs-to-complete-on-shutdown: true   # 是否等待所有定时任务执行完毕后再关闭
    startup-delay: 5s                 # 定时任务启动延迟(需要等待整个程序启动完成时使用)
    overwrite-existing-jobs: false    # 是否允许覆盖已存在的定时任务
    properties:
      org:
        quartz:
          # 调度器相关配置
          scheduler:
            instanceId: AUTO           # 实例id, AUTO = 自动生成
          # JobStore 相关配置
          jobStore:
            dataSource: quartzDataSource    # 使用的数据源名称
            class: org.quartz.impl.jdbcjobstore.JobStoreTX    # JobStore 实现类
            driverDelegateClass: org.quartz.impl.jdbcjobstore.StdJDBCDelegate  # 数据库"方言"
            tablePrefix: QRTZ_              # 表前缀, 默认 QRTZ_
            isClustered: true               # 是否是集群模式
            clusterCheckinInterval: 30000   # 集群检查间隔(毫秒)
            misfireThreshold: 60000         # 最多容忍一次执行晚 x(毫秒), 超时视为错过一次执行
            useProperties: true             # JobDataMaps 仅使用 string 格式处理其中数据
          # 线程池相关配置
          threadPool:
            class: org.quartz.simpl.SimpleThreadPool  # 线程池类型
            threadCount: 10       # 线程池大小, 1 ~ 100
            threadPriority: 5     # 线程优先级, 1(最小) ~ 10(最大), 默认 5
          # 数据源配置
          dataSource:
            # 这里的数据源名称需要与上文 spring.quartz.properties.org.quartz.jobStore.dataSource 对应
            quartzDataSource:
              connectionProvider:
                class: com.alibaba.druid.support.quartz.DruidQuartzConnectionProvider   # 连接池提供者
              url: jdbc:mysql://localhost:3306/quartz_jobs?createDatabaseIfNotExist=true&useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai&nullCatalogMeansCurrent=true&allowPublicKeyRetrieval=true
              username: root
              password: "xaTqi5!moNzx#noZcYr"
              validationQuery: "select 1 from dual"   # 验证可用性的 sql 查询语句

# 日志
logging:
  level:
    ROOT: info  # 最低展示级别 (error > warn > info > debug)
  pattern:
    file: '%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %highlight(%-5level) %green(%logger{50}).%M-%L - %msg %n'
    console: '%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %highlight(%-5level) %green(%logger{50}).%M-%L - %msg %n'
  logback:
    rolling policy:
      max-history: 10 # 最大保留时长(天)
      max-file-size: 100MB
  file:
    path: "logs"